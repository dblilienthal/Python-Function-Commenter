{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "sheet_delimiter": false
    }
   },
   "source": [
    "Link to datasets used in the project: <br> \n",
    "https://github.com/github/CodeSearchNet <br>\n",
    "https://www.kaggle.com/linkanjarad/coding-problems-and-solution-python-code?select=ProblemSolutionPythonV3.csv <br>\n",
    "https://www.kaggle.com/veeralakrishna/python-code-data <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "datalore": {
     "sheet_delimiter": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from multiprocessing import Pool\n",
    "import re\n",
    "import pysbd # For sentence segmentation\n",
    "from langdetect import detect_langs\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "sheet_delimiter": false
    }
   },
   "source": [
    "## Data Exploration and Pre-processing\n",
    "\n",
    "#### About the Data\n",
    "We used three different datasets for this project, two sourced from Kaggle and one provided by Github.\n",
    "\n",
    "The first two are a collection of different coding challenges from various sources such as w3resource, geeksforgeeks, etc. In these examples, there is usually a prompt written in plain English as well as a solution written in python code. The covered topics for the coding challenges include:\n",
    "* Working with strings, lists, arrays, tuples, dictionaries, CSV, JSON\n",
    "* Utilizing modules including NumPy, BeautifulSoup, tkinter, Pandas, random, os, re, datetime\n",
    "* File I/O\n",
    "* Loops and Conditionals\n",
    "* Functions (including Lambda) and Classes\n",
    "* OOP and DSA\n",
    "* Searching & Sorting\n",
    "* Pattern Printing \n",
    "\n",
    "Between these two datasets there are around 8000 examples of code and the matching prompt.\n",
    "\n",
    "Our third dataset is CodeSearchNet by Github. The full dataset contains 2 million comment and code pairs across multiple programming languages, but we will only be using a selection of those written in python for our purposes here. CodeSearchNet was originally intended to help improve code searching using natural language but should work well for the problem of code summarization as well. The codenet data contains more advanced functions, class definitions, and is inherently more complex than the coding challenge data. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "sheet_delimiter": false
    }
   },
   "source": [
    "#### Preprocessing Coding Challenge Data \n",
    "*Loading in the data from directory*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "datalore": {
     "sheet_delimiter": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Problem</th>\n",
       "      <th>Python Code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Write a NumPy program to repeat elements of an...</td>\n",
       "      <td>import numpy as np\\rx = np.repeat(3, 4)\\rprint...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Write a Python function to create and print a ...</td>\n",
       "      <td>def printValues():\\n\\tl = list()\\n\\tfor i in r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Write a Python program to remove duplicates fr...</td>\n",
       "      <td>import itertools\\rnum = [[10, 20], [40], [30, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Write a NumPy program to compute the x and y c...</td>\n",
       "      <td>import numpy as np\\rimport matplotlib.pyplot a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Write a Python program to alter a given SQLite...</td>\n",
       "      <td>import sqlite3\\rfrom sqlite3 import Error\\rdef...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Problem  \\\n",
       "0  Write a NumPy program to repeat elements of an...   \n",
       "1  Write a Python function to create and print a ...   \n",
       "2  Write a Python program to remove duplicates fr...   \n",
       "3  Write a NumPy program to compute the x and y c...   \n",
       "4  Write a Python program to alter a given SQLite...   \n",
       "\n",
       "                                         Python Code  \n",
       "0  import numpy as np\\rx = np.repeat(3, 4)\\rprint...  \n",
       "1  def printValues():\\n\\tl = list()\\n\\tfor i in r...  \n",
       "2  import itertools\\rnum = [[10, 20], [40], [30, ...  \n",
       "3  import numpy as np\\rimport matplotlib.pyplot a...  \n",
       "4  import sqlite3\\rfrom sqlite3 import Error\\rdef...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://www.kaggle.com/linkanjarad/coding-problems-and-solution-python-code?select=ProblemSolutionPythonV3.csv\n",
    "df = pd.read_csv(\"Data/ProblemSolutionPythonV3.csv\", index_col=0) #small dataset 1\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Loading code data*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/veeralakrishna/python-code-data\n",
    "with open('Data/Python_code_data.txt', encoding=\"utf-8\") as f: #small dataset 2\n",
    "    lines = f.readlines()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "sheet_delimiter": false
    }
   },
   "source": [
    "#### Exploring a few samples from both datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########################################################################################################################\n",
      "###################### ------------------------------  Problem   ------------------------------ ######################\n",
      "######################################################################################################################## \n",
      "\n",
      "Write a Python Program for ShellSort\n",
      "\n",
      "########################################################################################################################\n",
      "###################### ------------------------------   Function   ------------------------------ ######################\n",
      "######################################################################################################################## \n",
      "\n",
      "# Python program for implementation of Shell Sort\n",
      "  \n",
      "def shellSort(arr):\n",
      "  \n",
      "    # Start with a big gap, then reduce the gap\n",
      "    n = len(arr)\n",
      "    gap = n/2\n",
      "  \n",
      "    # Do a gapped insertion sort for this gap size.\n",
      "    # The first gap elements a[0..gap-1] are already in gapped \n",
      "    # order keep adding one more element until the entire array\n",
      "    # is gap sorted\n",
      "    while gap > 0:\n",
      "  \n",
      "        for i in range(gap,n):\n",
      "  \n",
      "            # add a[i] to the elements that have been gap sorted\n",
      "            # save a[i] in temp and make a hole at position i\n",
      "            temp = arr[i]\n",
      "  \n",
      "            # shift earlier gap-sorted elements up until the correct\n",
      "            # location for a[i] is found\n",
      "            j = i\n",
      "            while  j >= gap and arr[j-gap] >temp:\n",
      "                arr[j] = arr[j-gap]\n",
      "                j -= gap\n",
      "  \n",
      "            # put temp (the original a[i]) in its correct location\n",
      "            arr[j] = temp\n",
      "        gap /= 2\n",
      "  \n",
      "  \n",
      "# Driver code to test above\n",
      "arr = [ 12, 34, 54, 2, 3]\n",
      "  \n",
      "n = len(arr)\n",
      "print (\"Array before sorting:\")\n",
      "for i in range(n):\n",
      "    print(arr[i]),\n",
      "  \n",
      "shellSort(arr)\n",
      "  \n",
      "print (\"\\nArray after sorting:\")\n",
      "for i in range(n):\n",
      "    print(arr[i]),\n",
      "  \n",
      "# This code is contributed by Mohit Kumra\n"
     ]
    }
   ],
   "source": [
    "rand_example = np.random.choice(df.shape[0])\n",
    "print(\"#\"*120 + \"\\n\" + \"#\"*22, \"-\"*30, \" Problem  \", \"-\"*30, \"#\"*22 + \"\\n\" + \"#\"*120, '\\n')\n",
    "print(df['Problem'].iloc[rand_example])\n",
    "print('\\n' + \"#\"*120 + \"\\n\" + \"#\"*22, \"-\"*30, \"  Function  \", \"-\"*30, \"#\"*22 + \"\\n\" + \"#\"*120, '\\n')\n",
    "print(df['Python Code'].iloc[rand_example])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########################################################################################################################\n",
      "###################### ------------------------------  Problem   ------------------------------ ######################\n",
      "######################################################################################################################## \n",
      "\n",
      "Write a Python program to parse a given CSV string and get the list of lists of string values. Use csv.reader\n",
      "\n",
      "########################################################################################################################\n",
      "###################### ------------------------------   Function   ------------------------------ ######################\n",
      "######################################################################################################################## \n",
      "\n",
      "import csv\r",
      "csv_string = \"\"\"1,2,3\r",
      "4,5,6\r",
      "7,8,9\r",
      "\"\"\"\r",
      "print(\"Original string:\")\r",
      "print(csv_string)\r",
      "lines = csv_string.splitlines()\r",
      "print(\"List of CSV formatted strings:\")\r",
      "print(lines)\r",
      "reader = csv.reader(lines)\r",
      "parsed_csv = list(reader)\r",
      "print(\"\\nList representation of the CSV file:\")\r",
      "print(parsed_csv)\r\n"
     ]
    }
   ],
   "source": [
    "rand_example = np.random.choice(df.shape[0])\n",
    "print(\"#\"*120 + \"\\n\" + \"#\"*22, \"-\"*30, \" Problem  \", \"-\"*30, \"#\"*22 + \"\\n\" + \"#\"*120, '\\n')\n",
    "print(df['Problem'].iloc[rand_example])\n",
    "print('\\n' + \"#\"*120 + \"\\n\" + \"#\"*22, \"-\"*30, \"  Function  \", \"-\"*30, \"#\"*22 + \"\\n\" + \"#\"*120, '\\n')\n",
    "print(df['Python Code'].iloc[rand_example])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########################################################################################################################\n",
      "###################### ------------------------------  Problem   ------------------------------ ######################\n",
      "######################################################################################################################## \n",
      "\n",
      "Write a Pandas program to create a time series object with a time zone. \n",
      "\n",
      "########################################################################################################################\n",
      "###################### ------------------------------   Function   ------------------------------ ######################\n",
      "######################################################################################################################## \n",
      "\n",
      "import pandas as pd\r",
      "print(\"Timezone: Europe/Berlin:\")\r",
      "print(\"Using pytz:\")\r",
      "date_pytz = pd.Timestamp('2019-01-01', tz = 'Europe/Berlin')\r",
      "print(date_pytz.tz)  \r",
      "print(\"Using dateutil:\")\r",
      "date_util = pd.Timestamp('2019-01-01', tz = 'dateutil/Europe/Berlin')\r",
      "print(date_util.tz)\r",
      "print(\"\\nUS/Pacific:\")\r",
      "print(\"Using pytz:\")\r",
      "date_pytz = pd.Timestamp('2019-01-01', tz = 'US/Pacific')\r",
      "print(date_pytz.tz)  \r",
      "print(\"Using dateutil:\")\r",
      "date_util = pd.Timestamp('2019-01-01', tz = 'dateutil/US/Pacific')\r",
      "print(date_util.tz)\r\n"
     ]
    }
   ],
   "source": [
    "rand_example = np.random.choice(df.shape[0])\n",
    "print(\"#\"*120 + \"\\n\" + \"#\"*22, \"-\"*30, \" Problem  \", \"-\"*30, \"#\"*22 + \"\\n\" + \"#\"*120, '\\n')\n",
    "print(df['Problem'].iloc[rand_example])\n",
    "print('\\n' + \"#\"*120 + \"\\n\" + \"#\"*22, \"-\"*30, \"  Function  \", \"-\"*30, \"#\"*22 + \"\\n\" + \"#\"*120, '\\n')\n",
    "print(df['Python Code'].iloc[rand_example])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# write a python program to add two numbers \n",
      "num1 = 1.5\n",
      "num2 = 6.3\n",
      "sum = num1 + num2\n",
      "print(f'Sum: {sum}')\n",
      "\n",
      "\n",
      "# write a python function to add two user provided numbers and return the sum\n",
      "def add_two_numbers(num1, num2):\n",
      "    sum = num1 + num2\n",
      "    return sum\n",
      "\n",
      "\n",
      "# write a program to find and print the largest among three numbers\n",
      "\n",
      "num1 = 10\n",
      "num2 = 12\n",
      "num3 = 14\n",
      "if (num1 >= num2) and (num1 >= num3):\n",
      "   largest = num1\n",
      "elif (num2 >= num1) and (num2 >= num3):\n",
      "   largest = num2\n",
      "else:\n",
      "   largest = num3\n",
      "print(f'largest:{largest}')\n",
      "\n",
      "\n",
      "# write a program to find and print the smallest among three numbers\n",
      "num1 = 10\n",
      "num2 = 12\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(''.join(lines[0:30]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "sheet_delimiter": false
    }
   },
   "source": [
    "#### Cleaning Coding Challenge Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "sheet_delimiter": false
    }
   },
   "source": [
    "Removing unnecessary language from the prompts, we do not need phrases like 'write a python function', 'write a numpy program', etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "datalore": {
     "sheet_delimiter": false
    }
   },
   "outputs": [],
   "source": [
    "#remove the first few words from the prompt 'write a python program' 'write a python function' ... etc\n",
    "df['Problem'] = df['Problem'].apply(lambda x: ' '.join(x.split()[5:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Looking at examples*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in an array\n"
     ]
    }
   ],
   "source": [
    "rand_example = np.random.choice(df.shape[0])\n",
    "print(df['Problem'].iloc[rand_example])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get the current date, oldest date and number of days between Current date and oldest date of Ufo dataset.\n"
     ]
    }
   ],
   "source": [
    "rand_example = np.random.choice(df.shape[0])\n",
    "print(df['Problem'].iloc[rand_example])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "create an array of all the even integers from 30 to 70.\n"
     ]
    }
   ],
   "source": [
    "rand_example = np.random.choice(df.shape[0])\n",
    "print(df['Problem'].iloc[rand_example])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cleaning the Python Code Data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "sheet_delimiter": false
    }
   },
   "source": [
    "For the second dataset, it was provided as a txt file so we needed to identify what lines are code and what lines are the problem prompts/comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "datalore": {
     "sheet_delimiter": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 7, 13, 27]\n",
      "# write a python program to add two numbers \n",
      "\n",
      "# write a python function to add two user provided numbers and return the sum\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# keep track of what lines in .txt file are used for comments, two lists that will eventually become the dataframe for \n",
    "# holding the prompt and holding the code\n",
    "comments = []\n",
    "comment_lines = []\n",
    "code = []\n",
    "\n",
    "# for each line, if it starts with a '#' character, save that line as a comment line\n",
    "for i in np.arange(len(lines)):\n",
    "    if(lines[i][0]=='#'):\n",
    "        comments.append(lines[i])\n",
    "        comment_lines.append(i)\n",
    "        \n",
    "# testing to see which lines are comment lines\n",
    "print(comment_lines[0:4])\n",
    "print(lines[0])\n",
    "print(lines[7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "datalore": {
     "sheet_delimiter": false
    }
   },
   "outputs": [],
   "source": [
    "# populate list of code\n",
    "for index, elem in enumerate(comment_lines):\n",
    "    if index+1 < len(comment_lines) and index - 1 >= 0:\n",
    "        prev = comment_lines[index-1]\n",
    "        code.append(lines[prev+1:elem])\n",
    "        \n",
    "# create dataframe\n",
    "df1 = pd.DataFrame(list(zip(comments,code)),columns=['comments','code'])\n",
    "\n",
    "#convert list of lines to one string\n",
    "df1['code'] = df1['code'].apply(lambda x: ' '.join(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Looking at examples*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########################################################################################################################\n",
      "###################### ------------------------------  Problem   ------------------------------ ######################\n",
      "######################################################################################################################## \n",
      "\n",
      "# Write a program to print the sum of squares of first n natural numbers\n",
      "\n",
      "\n",
      "########################################################################################################################\n",
      "###################### ------------------------------   Function   ------------------------------ ######################\n",
      "######################################################################################################################## \n",
      "\n",
      "n = 21\n",
      " sum_n = 0\n",
      " for i in range(1, n+1):\n",
      "     sum_n += i**2\n",
      " print(sum_n)\n",
      " \n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "rand_example = np.random.choice(df1.shape[0])\n",
    "print(\"#\"*120 + \"\\n\" + \"#\"*22, \"-\"*30, \" Problem  \", \"-\"*30, \"#\"*22 + \"\\n\" + \"#\"*120, '\\n')\n",
    "print(df1['comments'].iloc[rand_example])\n",
    "print('\\n' + \"#\"*120 + \"\\n\" + \"#\"*22, \"-\"*30, \"  Function  \", \"-\"*30, \"#\"*22 + \"\\n\" + \"#\"*120, '\\n')\n",
    "print(df1['code'].iloc[rand_example])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "sheet_delimiter": false
    }
   },
   "source": [
    "The second dataset was less organized so we have a bunch of different manual rules to clean the problem prompts and remove examples that could not be cleaned."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Cleaning df1*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "datalore": {
     "sheet_delimiter": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4111 clean examples\n",
      "845 remaining\n",
      "82.95 % clean\n"
     ]
    }
   ],
   "source": [
    "df1['comments'] = df1['comments'].str.lower()\n",
    "count = 0\n",
    "remaining = 0\n",
    "for row in df1['comments']:\n",
    "    if len(df1['comments'][count].split())<=3: #removes lines that only have two words\n",
    "        df1['comments'][count] = ''\n",
    "    df1['comments'][count] = df1['comments'][count].replace('# write a python program to ','')\n",
    "    df1['comments'][count] = df1['comments'][count].replace('# write a program to ','')\n",
    "    df1['comments'][count] = df1['comments'][count].replace('# write program to ','')\n",
    "    df1['comments'][count] = df1['comments'][count].replace('# write program which ','')\n",
    "    df1['comments'][count] = df1['comments'][count].replace('# write a program which ','')\n",
    "    df1['comments'][count] = df1['comments'][count].replace('# write a ','')\n",
    "    df1['comments'][count] = df1['comments'][count].replace('# write python code to demonstrate ','')\n",
    "    df1['comments'][count] = df1['comments'][count].replace('# write python3 code to demonstrate','')\n",
    "    df1['comments'][count] = df1['comments'][count].replace('# please write a program which ','')\n",
    "    df1['comments'][count] = df1['comments'][count].replace('# please write a program to ','')\n",
    "    df1['comments'][count] = df1['comments'][count].replace('# define a function that can ','')\n",
    "    df1['comments'][count] = df1['comments'][count].replace('# define a function which can ','')\n",
    "    if df1['comments'][count].find('write a program to')!=-1:\n",
    "        df1['comments'][count] = df1['comments'][count][df1['comments'][count].find('write a program to')+19:]\n",
    "    if df1['comments'][count].find('write a python program that')!=-1:\n",
    "        df1['comments'][count] = df1['comments'][count][df1['comments'][count].find('write a python program that')+28:]\n",
    "    if df1['comments'][count].find('function to')!=-1:\n",
    "        df1['comments'][count] = df1['comments'][count][df1['comments'][count].find('function to')+12:]\n",
    "    if df1['comments'][count].find('program to')!=-1:\n",
    "        df1['comments'][count] = df1['comments'][count][df1['comments'][count].find('program to')+11:]\n",
    "    if df1['comments'][count].find('define')!=-1 and df1['comments'][count].find('class')!=-1:\n",
    "        df1['comments'][count] = \"\"\n",
    "    if df1['comments'][count].find('# in[')!=-1:\n",
    "        df1['comments'][count] = \"\"\n",
    "    if df1['comments'][count].find('printing result')!=-1:\n",
    "        df1['comments'][count] = \"\"\n",
    "    if df1['comments'][count].find('code to')!=-1:\n",
    "        df1['comments'][count] = df1['comments'][count][df1['comments'][count].find('code to')+8:]\n",
    "    if df1['comments'][count].find('function that')!=-1:\n",
    "        df1['comments'][count] = df1['comments'][count][df1['comments'][count].find('function that')+14:]\n",
    "    if df1['comments'][count].find('function which')!=-1:\n",
    "        df1['comments'][count] = df1['comments'][count][df1['comments'][count].find('function which')+15:]\n",
    "    if df1['comments'][count].find('#')==0:\n",
    "        remaining+=1\n",
    "    count+=1\n",
    "print(df1.shape[0]-remaining,'clean examples')\n",
    "print(remaining, 'remaining')\n",
    "print(round(((df1.shape[0]-remaining)/df1.shape[0])*100,2) ,'% clean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "datalore": {
     "sheet_delimiter": false
    }
   },
   "outputs": [],
   "source": [
    "# replace empty prompts with null and then drop\n",
    "df1['comments'].replace('', np.nan, inplace=True)\n",
    "df1 = df1.dropna()\n",
    "\n",
    "# drop the remaining examples\n",
    "df1 = df1[df1['comments'].str.find('#') == -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*New amount of examples*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3735, 2)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "datalore": {
     "sheet_delimiter": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comments</th>\n",
       "      <th>code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>add two numbers \\n</td>\n",
       "      <td>num1 = 1.5\\n num2 = 6.3\\n sum = num1 + num2\\n ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>add two user provided numbers and return the s...</td>\n",
       "      <td>def add_two_numbers(num1, num2):\\n     sum = n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>find and print the largest among three numbers\\n</td>\n",
       "      <td>\\n num1 = 10\\n num2 = 12\\n num3 = 14\\n if (num...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>find and print the smallest among three numbers\\n</td>\n",
       "      <td>num1 = 10\\n num2 = 12\\n num3 = 14\\n if (num1 &lt;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>merge two given lists into one\\n</td>\n",
       "      <td>def merge_lists(l1, l2):\\n     return l1 + l2\\...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            comments  \\\n",
       "0                                 add two numbers \\n   \n",
       "1  add two user provided numbers and return the s...   \n",
       "2   find and print the largest among three numbers\\n   \n",
       "3  find and print the smallest among three numbers\\n   \n",
       "4                   merge two given lists into one\\n   \n",
       "\n",
       "                                                code  \n",
       "0  num1 = 1.5\\n num2 = 6.3\\n sum = num1 + num2\\n ...  \n",
       "1  def add_two_numbers(num1, num2):\\n     sum = n...  \n",
       "2  \\n num1 = 10\\n num2 = 12\\n num3 = 14\\n if (num...  \n",
       "3  num1 = 10\\n num2 = 12\\n num3 = 14\\n if (num1 <...  \n",
       "4  def merge_lists(l1, l2):\\n     return l1 + l2\\...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Combining both datasets**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "sheet_delimiter": false
    }
   },
   "source": [
    "Now that we have both datasets processed we can combine them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "datalore": {
     "sheet_delimiter": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['comments', 'code'], dtype='object')\n",
      "Index(['Problem', 'Python Code'], dtype='object')\n",
      "Index(['Problem', 'Python Code'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df1.columns)\n",
    "print(df.columns)\n",
    "df1.rename(columns={'comments':'Problem','code':'Python Code'},inplace=True)\n",
    "print(df1.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "datalore": {
     "sheet_delimiter": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7042, 2)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.append(df1)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "datalore": {
     "sheet_delimiter": false
    }
   },
   "outputs": [],
   "source": [
    "# lowercase everything\n",
    "df['Problem'] = df['Problem'].apply(lambda x: str(x).lower())\n",
    "df['Python Code'] = df['Python Code'].apply(lambda x: str(x).lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Removing imports and examples that are not functions*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Problem</th>\n",
       "      <th>Python Code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>create and print a list where the values are s...</td>\n",
       "      <td>def printvalues():\\n\\tl = list()\\n\\tfor i in r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>alter a given sqlite table.</td>\n",
       "      <td>def sql_connection():\\r   try:\\r     conn = sq...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>extract specified size of strings from a give ...</td>\n",
       "      <td>def extract_string(str_list1, l):\\r    result ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sort unsorted numbers using strand sort.</td>\n",
       "      <td>def strand_sort(arr: list, reverse: bool = fal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>insert a specified element in a given list aft...</td>\n",
       "      <td>def inset_element_list(lst, x, n):\\r    i = n\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3152</th>\n",
       "      <td>program using generator to print the numbers w...</td>\n",
       "      <td>def numgenerator(n):\\n     for i in range(n+1)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3153</th>\n",
       "      <td>searches an item in a sorted list. the functio...</td>\n",
       "      <td>def bin_search(li, element):\\n     bottom = 0\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3154</th>\n",
       "      <td>searches an item in a sorted list. the functio...</td>\n",
       "      <td>def bin_search(li, element):\\n     bottom = 0\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3155</th>\n",
       "      <td>print this list after removing all duplicate v...</td>\n",
       "      <td>def removeduplicate( li ):\\n     newli=[]\\n   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3156</th>\n",
       "      <td>solve a classic ancient chinese puzzle:  we co...</td>\n",
       "      <td>def solve(numheads,numlegs):\\n     ns='no solu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3157 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Problem  \\\n",
       "0     create and print a list where the values are s...   \n",
       "1                           alter a given sqlite table.   \n",
       "2     extract specified size of strings from a give ...   \n",
       "3              sort unsorted numbers using strand sort.   \n",
       "4     insert a specified element in a given list aft...   \n",
       "...                                                 ...   \n",
       "3152  program using generator to print the numbers w...   \n",
       "3153  searches an item in a sorted list. the functio...   \n",
       "3154  searches an item in a sorted list. the functio...   \n",
       "3155  print this list after removing all duplicate v...   \n",
       "3156  solve a classic ancient chinese puzzle:  we co...   \n",
       "\n",
       "                                            Python Code  \n",
       "0     def printvalues():\\n\\tl = list()\\n\\tfor i in r...  \n",
       "1     def sql_connection():\\r   try:\\r     conn = sq...  \n",
       "2     def extract_string(str_list1, l):\\r    result ...  \n",
       "3     def strand_sort(arr: list, reverse: bool = fal...  \n",
       "4     def inset_element_list(lst, x, n):\\r    i = n\\...  \n",
       "...                                                 ...  \n",
       "3152  def numgenerator(n):\\n     for i in range(n+1)...  \n",
       "3153  def bin_search(li, element):\\n     bottom = 0\\...  \n",
       "3154  def bin_search(li, element):\\n     bottom = 0\\...  \n",
       "3155  def removeduplicate( li ):\\n     newli=[]\\n   ...  \n",
       "3156  def solve(numheads,numlegs):\\n     ns='no solu...  \n",
       "\n",
       "[3157 rows x 2 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(df.shape[0]):\n",
    "    index = df['Python Code'].iloc[i].find('def')\n",
    "    if index != -1:\n",
    "        df['Python Code'].iloc[i] = df['Python Code'].iloc[i][index:]\n",
    "        \n",
    "# Removing any examples that are not functions \n",
    "df = df[df['Python Code'].str.find('def') != -1]\n",
    "df = df.reset_index(drop=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Spacing out the code for easier tokenization*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Problem</th>\n",
       "      <th>Python Code</th>\n",
       "      <th>Python Code Cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>create and print a list where the values are s...</td>\n",
       "      <td>def printvalues():\\n\\tl = list()\\n\\tfor i in r...</td>\n",
       "      <td>def printvalues ( ) : l = list ( ) for i in ra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>alter a given sqlite table.</td>\n",
       "      <td>def sql_connection():\\r   try:\\r     conn = sq...</td>\n",
       "      <td>def sql_connection ( ) : try : conn = sqlite3....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>extract specified size of strings from a give ...</td>\n",
       "      <td>def extract_string(str_list1, l):\\r    result ...</td>\n",
       "      <td>def extract_string ( str_list1 , l ) : result ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sort unsorted numbers using strand sort.</td>\n",
       "      <td>def strand_sort(arr: list, reverse: bool = fal...</td>\n",
       "      <td>def strand_sort ( arr : list , reverse : bool ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>insert a specified element in a given list aft...</td>\n",
       "      <td>def inset_element_list(lst, x, n):\\r    i = n\\...</td>\n",
       "      <td>def inset_element_list ( lst , x , n ) : i = n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3152</th>\n",
       "      <td>program using generator to print the numbers w...</td>\n",
       "      <td>def numgenerator(n):\\n     for i in range(n+1)...</td>\n",
       "      <td>def numgenerator ( n ) : for i in range ( n + ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3153</th>\n",
       "      <td>searches an item in a sorted list. the functio...</td>\n",
       "      <td>def bin_search(li, element):\\n     bottom = 0\\...</td>\n",
       "      <td>def bin_search ( li , element ) : bottom = 0 t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3154</th>\n",
       "      <td>searches an item in a sorted list. the functio...</td>\n",
       "      <td>def bin_search(li, element):\\n     bottom = 0\\...</td>\n",
       "      <td>def bin_search ( li , element ) : bottom = 0 t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3155</th>\n",
       "      <td>print this list after removing all duplicate v...</td>\n",
       "      <td>def removeduplicate( li ):\\n     newli=[]\\n   ...</td>\n",
       "      <td>def removeduplicate ( li ) : newli = [ ] seen ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3156</th>\n",
       "      <td>solve a classic ancient chinese puzzle:  we co...</td>\n",
       "      <td>def solve(numheads,numlegs):\\n     ns='no solu...</td>\n",
       "      <td>def solve ( numheads , numlegs ) : ns = ' no s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3157 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Problem  \\\n",
       "0     create and print a list where the values are s...   \n",
       "1                           alter a given sqlite table.   \n",
       "2     extract specified size of strings from a give ...   \n",
       "3              sort unsorted numbers using strand sort.   \n",
       "4     insert a specified element in a given list aft...   \n",
       "...                                                 ...   \n",
       "3152  program using generator to print the numbers w...   \n",
       "3153  searches an item in a sorted list. the functio...   \n",
       "3154  searches an item in a sorted list. the functio...   \n",
       "3155  print this list after removing all duplicate v...   \n",
       "3156  solve a classic ancient chinese puzzle:  we co...   \n",
       "\n",
       "                                            Python Code  \\\n",
       "0     def printvalues():\\n\\tl = list()\\n\\tfor i in r...   \n",
       "1     def sql_connection():\\r   try:\\r     conn = sq...   \n",
       "2     def extract_string(str_list1, l):\\r    result ...   \n",
       "3     def strand_sort(arr: list, reverse: bool = fal...   \n",
       "4     def inset_element_list(lst, x, n):\\r    i = n\\...   \n",
       "...                                                 ...   \n",
       "3152  def numgenerator(n):\\n     for i in range(n+1)...   \n",
       "3153  def bin_search(li, element):\\n     bottom = 0\\...   \n",
       "3154  def bin_search(li, element):\\n     bottom = 0\\...   \n",
       "3155  def removeduplicate( li ):\\n     newli=[]\\n   ...   \n",
       "3156  def solve(numheads,numlegs):\\n     ns='no solu...   \n",
       "\n",
       "                                    Python Code Cleaned  \n",
       "0     def printvalues ( ) : l = list ( ) for i in ra...  \n",
       "1     def sql_connection ( ) : try : conn = sqlite3....  \n",
       "2     def extract_string ( str_list1 , l ) : result ...  \n",
       "3     def strand_sort ( arr : list , reverse : bool ...  \n",
       "4     def inset_element_list ( lst , x , n ) : i = n...  \n",
       "...                                                 ...  \n",
       "3152  def numgenerator ( n ) : for i in range ( n + ...  \n",
       "3153  def bin_search ( li , element ) : bottom = 0 t...  \n",
       "3154  def bin_search ( li , element ) : bottom = 0 t...  \n",
       "3155  def removeduplicate ( li ) : newli = [ ] seen ...  \n",
       "3156  def solve ( numheads , numlegs ) : ns = ' no s...  \n",
       "\n",
       "[3157 rows x 3 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_function(text):\n",
    "    text_split = str(text).replace('\\n',' ').replace('\\t',' ').replace(',', ' , ').split()\n",
    "    text = ' '.join(text_split)\n",
    "    text = (text.replace('(', ' ( ').replace(')', ' ) ')\n",
    "            .replace('=',' = ').replace('\"', ' \" ')\n",
    "            .replace(\"'\", \" ' \").replace(\"#\",\" # \")\n",
    "            .replace('[',' [ ').replace(']', ' ] ')\n",
    "            .replace('{',' { ').replace('}', ' } ')\n",
    "            .replace('+', ' + ').replace('-', ' - ')\n",
    "            .replace(':', ' : ').replace('  ',' '))\n",
    "    return text\n",
    "\n",
    "df['Python Code Cleaned'] = df['Python Code'].apply(clean_function)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Saving the dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv('./Data/Python_code_cleaned.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "sheet_delimiter": false
    }
   },
   "source": [
    "### Preprocessing the CodeNet dataset\n",
    "\n",
    "*Loading in data from directory*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "datalore": {
     "sheet_delimiter": false
    }
   },
   "outputs": [],
   "source": [
    "data_dir = './Data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "datalore": {
     "sheet_delimiter": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>docstring</th>\n",
       "      <th>function</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Trains a k-nearest neighbors classifier for fa...</td>\n",
       "      <td>def train(train_dir, model_save_path=None, n_n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Recognizes faces in given image using a traine...</td>\n",
       "      <td>def predict(X_img_path, knn_clf=None, model_pa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Shows the face recognition results visually.\\n...</td>\n",
       "      <td>def show_prediction_labels_on_image(img_path, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Convert a dlib 'rect' object to a plain tuple ...</td>\n",
       "      <td>def _rect_to_css(rect):\\n    \"\"\"\\n    Convert ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Make sure a tuple in (top, right, bottom, left...</td>\n",
       "      <td>def _trim_css_to_bounds(css, image_shape):\\n  ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           docstring  \\\n",
       "0  Trains a k-nearest neighbors classifier for fa...   \n",
       "1  Recognizes faces in given image using a traine...   \n",
       "2  Shows the face recognition results visually.\\n...   \n",
       "3  Convert a dlib 'rect' object to a plain tuple ...   \n",
       "4  Make sure a tuple in (top, right, bottom, left...   \n",
       "\n",
       "                                            function  \n",
       "0  def train(train_dir, model_save_path=None, n_n...  \n",
       "1  def predict(X_img_path, knn_clf=None, model_pa...  \n",
       "2  def show_prediction_labels_on_image(img_path, ...  \n",
       "3  def _rect_to_css(rect):\\n    \"\"\"\\n    Convert ...  \n",
       "4  def _trim_css_to_bounds(css, image_shape):\\n  ...  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "codenet = pd.read_csv(os.path.join(data_dir, 'CodeNetData.csv'))\n",
    "codenet.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "sheet_delimiter": false
    }
   },
   "source": [
    "Size of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "datalore": {
     "sheet_delimiter": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(503502, 2)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "codenet.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "sheet_delimiter": false
    }
   },
   "source": [
    "**Exploring some random samples**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "sheet_delimiter": false
    }
   },
   "source": [
    "*Click the cell below multiple times for different examples*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "datalore": {
     "sheet_delimiter": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########################################################################################################################\n",
      "###################### ------------------------------  Docstring   ------------------------------ ######################\n",
      "######################################################################################################################## \n",
      "\n",
      "setup root logger with ColoredFormatter.\n",
      "\n",
      "########################################################################################################################\n",
      "###################### ------------------------------   Function   ------------------------------ ######################\n",
      "######################################################################################################################## \n",
      "\n",
      "def setup_logger(log_level, log_file=None):\n",
      "    \"\"\"setup root logger with ColoredFormatter.\"\"\"\n",
      "    level = getattr(logging, log_level.upper(), None)\n",
      "    if not level:\n",
      "        color_print(\"Invalid log level: %s\" % log_level, \"RED\")\n",
      "        sys.exit(1)\n",
      "\n",
      "    # hide traceback when log level is INFO/WARNING/ERROR/CRITICAL\n",
      "    if level >= logging.INFO:\n",
      "        sys.tracebacklimit = 0\n",
      "\n",
      "    formatter = ColoredFormatter(\n",
      "        u\"%(log_color)s%(bg_white)s%(levelname)-8s%(reset)s %(message)s\",\n",
      "        datefmt=None,\n",
      "        reset=True,\n",
      "        log_colors=log_colors_config\n",
      "    )\n",
      "\n",
      "    if log_file:\n",
      "        handler = logging.FileHandler(log_file, encoding=\"utf-8\")\n",
      "    else:\n",
      "        handler = logging.StreamHandler()\n",
      "\n",
      "    handler.setFormatter(formatter)\n",
      "    logger.addHandler(handler)\n",
      "    logger.setLevel(level)\n"
     ]
    }
   ],
   "source": [
    "rand_example = np.random.choice(codenet.shape[0])\n",
    "print(\"#\"*120 + \"\\n\" + \"#\"*22, \"-\"*30, \" Docstring  \", \"-\"*30, \"#\"*22 + \"\\n\" + \"#\"*120, '\\n')\n",
    "print(codenet['docstring'].iloc[rand_example])\n",
    "print('\\n' + \"#\"*120 + \"\\n\" + \"#\"*22, \"-\"*30, \"  Function  \", \"-\"*30, \"#\"*22 + \"\\n\" + \"#\"*120, '\\n')\n",
    "print(codenet['function'].iloc[rand_example])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########################################################################################################################\n",
      "###################### ------------------------------  Docstring   ------------------------------ ######################\n",
      "######################################################################################################################## \n",
      "\n",
      "Deploys a file to the Artifactory BEL namespace cache\n",
      "\n",
      "    :param str filename: The physical path\n",
      "    :param str module_name: The name of the module to deploy to\n",
      "    :param tuple[str] auth: A pair of (str username, str password) to give to the auth keyword of the constructor of\n",
      "                            :class:`artifactory.ArtifactoryPath`. Defaults to the result of :func:`get_arty_auth`.\n",
      "    :return: The resource path, if it was deployed successfully, else none.\n",
      "    :rtype: Optional[str]\n",
      "\n",
      "########################################################################################################################\n",
      "###################### ------------------------------   Function   ------------------------------ ######################\n",
      "######################################################################################################################## \n",
      "\n",
      "def _deploy_helper(filename, module_name, get_module, get_today_fn, hash_check=True, auth=None):\n",
      "    \"\"\"Deploys a file to the Artifactory BEL namespace cache\n",
      "\n",
      "    :param str filename: The physical path\n",
      "    :param str module_name: The name of the module to deploy to\n",
      "    :param tuple[str] auth: A pair of (str username, str password) to give to the auth keyword of the constructor of\n",
      "                            :class:`artifactory.ArtifactoryPath`. Defaults to the result of :func:`get_arty_auth`.\n",
      "    :return: The resource path, if it was deployed successfully, else none.\n",
      "    :rtype: Optional[str]\n",
      "    \"\"\"\n",
      "    path = ArtifactoryPath(\n",
      "        get_module(module_name),\n",
      "        auth=get_arty_auth() if auth is None else auth\n",
      "    )\n",
      "    path.mkdir(exist_ok=True)\n",
      "\n",
      "    if hash_check:\n",
      "        deployed_semantic_hashes = {\n",
      "            get_bel_resource_hash(subpath.as_posix())\n",
      "            for subpath in path\n",
      "        }\n",
      "\n",
      "        semantic_hash = get_bel_resource_hash(filename)\n",
      "\n",
      "        if semantic_hash in deployed_semantic_hashes:\n",
      "            return  # Don't deploy if it's already uploaded\n",
      "\n",
      "    target = path / get_today_fn(module_name)\n",
      "    target.deploy_file(filename)\n",
      "\n",
      "    log.info('deployed %s', module_name)\n",
      "\n",
      "    return target.as_posix()\n"
     ]
    }
   ],
   "source": [
    "rand_example = np.random.choice(codenet.shape[0])\n",
    "print(\"#\"*120 + \"\\n\" + \"#\"*22, \"-\"*30, \" Docstring  \", \"-\"*30, \"#\"*22 + \"\\n\" + \"#\"*120, '\\n')\n",
    "print(codenet['docstring'].iloc[rand_example])\n",
    "print('\\n' + \"#\"*120 + \"\\n\" + \"#\"*22, \"-\"*30, \"  Function  \", \"-\"*30, \"#\"*22 + \"\\n\" + \"#\"*120, '\\n')\n",
    "print(codenet['function'].iloc[rand_example])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########################################################################################################################\n",
      "###################### ------------------------------  Docstring   ------------------------------ ######################\n",
      "######################################################################################################################## \n",
      "\n",
      "Remove sphinx-tabs CSS and JS asset files if not used in a page\n",
      "\n",
      "########################################################################################################################\n",
      "###################### ------------------------------   Function   ------------------------------ ######################\n",
      "######################################################################################################################## \n",
      "\n",
      "def update_context(app, pagename, templatename, context, doctree):\n",
      "    \"\"\" Remove sphinx-tabs CSS and JS asset files if not used in a page \"\"\"\n",
      "    if doctree is None:\n",
      "        return\n",
      "    visitor = _FindTabsDirectiveVisitor(doctree)\n",
      "    doctree.walk(visitor)\n",
      "    if not visitor.found_tabs_directive:\n",
      "        paths = [posixpath.join('_static', 'sphinx_tabs/' + f) for f in FILES]\n",
      "        if 'css_files' in context:\n",
      "            context['css_files'] = context['css_files'][:]\n",
      "            for path in paths:\n",
      "                if path.endswith('.css'):\n",
      "                    context['css_files'].remove(path)\n",
      "        if 'script_files' in context:\n",
      "            context['script_files'] = context['script_files'][:]\n",
      "            for path in paths:\n",
      "                if path.endswith('.js'):\n",
      "                    context['script_files'].remove(path)\n"
     ]
    }
   ],
   "source": [
    "rand_example = np.random.choice(codenet.shape[0])\n",
    "print(\"#\"*120 + \"\\n\" + \"#\"*22, \"-\"*30, \" Docstring  \", \"-\"*30, \"#\"*22 + \"\\n\" + \"#\"*120, '\\n')\n",
    "print(codenet['docstring'].iloc[rand_example])\n",
    "print('\\n' + \"#\"*120 + \"\\n\" + \"#\"*22, \"-\"*30, \"  Function  \", \"-\"*30, \"#\"*22 + \"\\n\" + \"#\"*120, '\\n')\n",
    "print(codenet['function'].iloc[rand_example])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "sheet_delimiter": false
    }
   },
   "source": [
    "#### Steps for cleaning the docstrings and functions\n",
    "\n",
    "**Docstring** <br>\n",
    "1. Remove the line breaks\n",
    "2. Remove the tabs\n",
    "3. Remove the examples that starts with `return`, `Args`, `:param`, or `Parameters`\n",
    "4. Remove the examples that are in another language\n",
    "5. Remove the examples that contain more characters than just a `,` or `.` (No extra characters)\n",
    "6. Remove `,` from examples \n",
    "7. Lowercase everything\n",
    "8. Remove everything after the first sentence\n",
    "9. Remove the period after the end of the sentence\n",
    "10. Remove examples that are less than 3 words and more than 20\n",
    "11. Remove any missing or blank examples\n",
    "\n",
    "**Function** <br>\n",
    "1. Remove everything between triple quotes\n",
    "2. Remove functions that have more than 100 words or so\n",
    "3. Remove any tabs, line breaks, extra white spaces and add spacing between commas, parentheses, and equal signs\n",
    "5. Remove any missing or blank examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "sheet_delimiter": false
    }
   },
   "source": [
    "*Note: running the code below can take a long time to process the data (45+ minutes sometimes). You can skip all the pre-processing steps and load in the cleaned data below. The step that takes this long is using the language detection (step 4) to remove any examples that are not in English on 500k+ examples. Even multi-threading this operations takes around 10 minutes on 14 cores.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "datalore": {
     "sheet_delimiter": false
    }
   },
   "outputs": [],
   "source": [
    "#codenet = pd.read_csv(os.path.join(data_dir, 'CodeNetData_cleaned.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "sheet_delimiter": false
    }
   },
   "source": [
    "**Cleaning docstring**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "datalore": {
     "sheet_delimiter": false
    }
   },
   "outputs": [],
   "source": [
    "### Step 1\n",
    "codenet['docstring_cleaned'] = codenet['docstring'].apply(lambda x: str(x).split('\\n\\n')[0])\n",
    "\n",
    "### Step 2\n",
    "codenet['docstring_cleaned'] = codenet['docstring_cleaned'].apply(lambda x: ' '.join(str(x).replace('\\n',' ').split()))\n",
    "\n",
    "### Step 3\n",
    "codenet['docstring_cleaned'] = codenet['docstring_cleaned'].apply(lambda x: x[:(None if str(x).find(':return:') == -1 else str(x).find(':return:'))])\n",
    "codenet['docstring_cleaned'] = codenet['docstring_cleaned'].apply(lambda x: x[:(None if str(x).find('Args') == -1 else str(x).find('Args'))])\n",
    "codenet['docstring_cleaned'] = codenet['docstring_cleaned'].apply(lambda x: x[:(None if str(x).find(':param') == -1 else str(x).find(':param'))])\n",
    "codenet['docstring_cleaned'] = codenet['docstring_cleaned'].apply(lambda x: x[:(None if str(x).find('Parameters') == -1 else str(x).find('Parameters'))])\n",
    "\n",
    "### Step 4\n",
    "from f import add_features\n",
    "# def detectEnglish(input):\n",
    "#     try:\n",
    "#         if(detect_langs(input)[0].lang==\"en\"):\n",
    "#             return True\n",
    "#         else: \n",
    "#             return False\n",
    "#     except:\n",
    "#         return False\n",
    "\n",
    "# def add_features(df):       \n",
    "#     df['docstring_isEnglish'] = df['docstring'].apply(lambda x: detectEnglish(str(x)))\n",
    "#     return df\n",
    "\n",
    "def parallelize_dataframe(df, func, n_cores=8):\n",
    "    df_split = np.array_split(df, n_cores)\n",
    "    pool = Pool(n_cores)\n",
    "    df = pd.concat(pool.map(func, df_split))\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    return df\n",
    "\n",
    "codenet = parallelize_dataframe(codenet, add_features, n_cores=14) # Multi-threading \n",
    "codenet = codenet[codenet['docstring_isEnglish'] == True]\n",
    "codenet = codenet.reset_index(drop=True) # reseting the index\n",
    "\n",
    "### Step 5\n",
    "codenet = codenet[codenet['docstring_cleaned'].apply(lambda x: x.replace(' ','').replace(',','').replace('.','').isalpha())]\n",
    "codenet = codenet.reset_index(drop=True)\n",
    "\n",
    "### Step 6\n",
    "codenet['docstring_cleaned'] = codenet['docstring_cleaned'].apply(lambda x: str(x).replace(',',''))\n",
    "\n",
    "### Step 7\n",
    "codenet['docstring_cleaned'] = codenet['docstring_cleaned'].apply(lambda x: str(x).lower())\n",
    "\n",
    "### Step 8\n",
    "seg = pysbd.Segmenter(language=\"en\", clean=False)\n",
    "codenet['docstring_cleaned'] = codenet['docstring_cleaned'].apply(lambda x: seg.segment(x)[0])\n",
    "\n",
    "### Step 9\n",
    "codenet['docstring_cleaned'] = codenet['docstring_cleaned'].apply(lambda x: str(x).rstrip('.'))\n",
    "\n",
    "### Step 10\n",
    "codenet = codenet[codenet['docstring_cleaned'].apply(lambda x: len(x.split()) > 2)]\n",
    "codenet = codenet[codenet['docstring_cleaned'].apply(lambda x: len(x.split()) < 21)]\n",
    "\n",
    "### Step 11\n",
    "codenet = codenet[codenet['docstring_cleaned'].astype(str) != ''] # Removing any docstrings that are empty\n",
    "codenet = codenet[codenet['docstring_cleaned'].isna() == False]\n",
    "codenet = codenet[codenet[\"docstring_cleaned\"].astype(str) != 'None']\n",
    "codenet = codenet.reset_index(drop=True) # reseting the index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "sheet_delimiter": false
    }
   },
   "source": [
    "*Looking at the cleaned examples now*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "datalore": {
     "sheet_delimiter": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned docstring: wait for the job to complete or a timeout to happen\n",
      "\n",
      "Old docstring: Wait for the job to complete, or a timeout to happen.\n",
      "\n",
      "      This is more efficient than the version in the base Job class, in that we can\n",
      "      use a call that blocks for the poll duration rather than a sleep. That means we\n",
      "      shouldn't block unnecessarily long and can also poll less.\n",
      "\n",
      "    Args:\n",
      "      timeout: how long to wait (in seconds) before giving up; default None which means no timeout.\n",
      "\n",
      "    Returns:\n",
      "      The QueryJob\n"
     ]
    }
   ],
   "source": [
    "rand_example = np.random.choice(codenet.shape[0])\n",
    "print(f'Cleaned docstring: {codenet[\"docstring_cleaned\"].iloc[rand_example]}\\n')\n",
    "print(f'Old docstring: {codenet[\"docstring\"].iloc[rand_example]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned docstring: get the values for the convolutionfilter record\n",
      "\n",
      "Old docstring: Get the values for the CONVOLUTIONFILTER record.\n"
     ]
    }
   ],
   "source": [
    "rand_example = np.random.choice(codenet.shape[0])\n",
    "print(f'Cleaned docstring: {codenet[\"docstring_cleaned\"].iloc[rand_example]}\\n')\n",
    "print(f'Old docstring: {codenet[\"docstring\"].iloc[rand_example]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned docstring: add a resource attribute attribute to a resource\n",
      "\n",
      "Old docstring: Add a resource attribute attribute to a resource.\n",
      "\n",
      "        attr_is_var indicates whether the attribute is a variable or not --\n",
      "        this is used in simulation to indicate that this value is expected\n",
      "        to be filled in by the simulator.\n"
     ]
    }
   ],
   "source": [
    "rand_example = np.random.choice(codenet.shape[0])\n",
    "print(f'Cleaned docstring: {codenet[\"docstring_cleaned\"].iloc[rand_example]}\\n')\n",
    "print(f'Old docstring: {codenet[\"docstring\"].iloc[rand_example]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "sheet_delimiter": false
    }
   },
   "source": [
    "**Cleaning Functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "datalore": {
     "sheet_delimiter": false
    }
   },
   "outputs": [],
   "source": [
    "### Step 1\n",
    "def remove_pydocs_doubleQ(text):\n",
    "    text = str(text)\n",
    "    try:\n",
    "        indexes_to_remove = []\n",
    "        for match in re.finditer('\"\"\"', text):\n",
    "            indexes_to_remove.append(match.start())  \n",
    "        return text[:indexes_to_remove[0]] + text[indexes_to_remove[1]+3:]\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "codenet['function_cleaned'] = codenet['function'].apply(remove_pydocs_doubleQ)\n",
    "\n",
    "### Step 2\n",
    "codenet = codenet[codenet['function_cleaned'].apply(lambda x: len(str(x).split())) < 101]\n",
    "\n",
    "### Step 3\n",
    "def clean_function(text):\n",
    "    text_split = str(text).replace('\\n',' ').replace('\\t',' ').replace(',', ' , ').split()\n",
    "    text = ' '.join(text_split)\n",
    "    text = (text.replace('(', ' ( ').replace(')', ' ) ')\n",
    "            .replace('=',' = ').replace('\"', ' \" ')\n",
    "            .replace(\"'\", \" ' \").replace(\"#\",\" # \")\n",
    "            .replace('[',' [ ').replace(']', ' ] ')\n",
    "            .replace('{',' { ').replace('}', ' } ')\n",
    "            .replace('+', ' + ').replace('-', ' - ')\n",
    "            .replace(':', ' : ').replace('  ',' '))\n",
    "    return text\n",
    "\n",
    "codenet['function_cleaned'] = codenet['function_cleaned'].apply(clean_function)\n",
    "\n",
    "### Step 4\n",
    "codenet = codenet[codenet['function_cleaned'].astype(str) != ''] # Removing any functions that are empty\n",
    "codenet = codenet[codenet['function_cleaned'].isna() == False] \n",
    "codenet = codenet[codenet[\"function_cleaned\"].astype(str) != 'None']\n",
    "codenet = codenet.reset_index(drop=True) # reseting the index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "sheet_delimiter": false
    }
   },
   "source": [
    "*Looking at the cleaned functions*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "datalore": {
     "sheet_delimiter": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned function: \n",
      "def set_x_grid_info ( self , x_low , x_high , num_x , xscale , xval_name ) : self._set_grid_info ( ' x ' , x_low , x_high , num_x , xscale , xval_name ) return\n",
      "\n",
      "Old function: \n",
      "def set_x_grid_info(self, x_low, x_high, num_x, xscale, xval_name):\n",
      "        \"\"\"Set the grid values for x.\n",
      "\n",
      "        Create information for the grid of x values.\n",
      "\n",
      "        Args:\n",
      "            num_x (int): Number of points on axis.\n",
      "            x_low/x_high (float): Lowest/highest value for the axis.\n",
      "            xscale (str): Scale of the axis. Choices are 'log' or 'lin'.\n",
      "            xval_name (str): Name representing the axis. See GenerateContainer documentation\n",
      "                for options for the name.\n",
      "\n",
      "        \"\"\"\n",
      "        self._set_grid_info('x', x_low, x_high, num_x, xscale, xval_name)\n",
      "        return\n"
     ]
    }
   ],
   "source": [
    "rand_example = np.random.choice(codenet.shape[0])\n",
    "print(f'Cleaned function: \\n{codenet[\"function_cleaned\"].iloc[rand_example]}\\n')\n",
    "print(f'Old function: \\n{codenet[\"function\"].iloc[rand_example]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned function: \n",
      "def getPageFontList ( self , pno ) : if self.isClosed or self.isEncrypted : raise ValueError ( \" operation illegal for closed / encrypted doc \" ) if self.isPDF : return self._getPageInfo ( pno , 1 ) return [ ] \n",
      "\n",
      "Old function: \n",
      "def getPageFontList(self, pno):\n",
      "        \"\"\"Retrieve a list of fonts used on a page.\n",
      "        \"\"\"\n",
      "        if self.isClosed or self.isEncrypted:\n",
      "            raise ValueError(\"operation illegal for closed / encrypted doc\")\n",
      "        if self.isPDF:\n",
      "            return self._getPageInfo(pno, 1)\n",
      "        return []\n"
     ]
    }
   ],
   "source": [
    "rand_example = np.random.choice(codenet.shape[0])\n",
    "print(f'Cleaned function: \\n{codenet[\"function_cleaned\"].iloc[rand_example]}\\n')\n",
    "print(f'Old function: \\n{codenet[\"function\"].iloc[rand_example]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "sheet_delimiter": false
    }
   },
   "source": [
    "New shape of the pre-processed dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "datalore": {
     "sheet_delimiter": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(201644, 5)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "codenet.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "datalore": {
     "sheet_delimiter": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>docstring</th>\n",
       "      <th>function</th>\n",
       "      <th>docstring_cleaned</th>\n",
       "      <th>docstring_isEnglish</th>\n",
       "      <th>function_cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Returns an array of bounding boxes of human fa...</td>\n",
       "      <td>def _raw_face_locations(img, number_of_times_t...</td>\n",
       "      <td>returns an array of bounding boxes of human fa...</td>\n",
       "      <td>True</td>\n",
       "      <td>def _raw_face_locations ( img , number_of_time...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Returns an array of bounding boxes of human fa...</td>\n",
       "      <td>def face_locations(img, number_of_times_to_ups...</td>\n",
       "      <td>returns an array of bounding boxes of human fa...</td>\n",
       "      <td>True</td>\n",
       "      <td>def face_locations ( img , number_of_times_to_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Return the Catalyst datatype from the size of ...</td>\n",
       "      <td>def _int_size_to_type(size):\\n    \"\"\"\\n    Ret...</td>\n",
       "      <td>return the catalyst datatype from the size of ...</td>\n",
       "      <td>True</td>\n",
       "      <td>def _int_size_to_type ( size ) : if size &lt; = 8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Convert a schema from Spark to Arrow</td>\n",
       "      <td>def to_arrow_schema(schema):\\n    \"\"\" Convert ...</td>\n",
       "      <td>convert a schema from spark to arrow</td>\n",
       "      <td>True</td>\n",
       "      <td>def to_arrow_schema ( schema ) : import pyarro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Convert schema from Arrow to Spark.</td>\n",
       "      <td>def from_arrow_schema(arrow_schema):\\n    \"\"\" ...</td>\n",
       "      <td>convert schema from arrow to spark</td>\n",
       "      <td>True</td>\n",
       "      <td>def from_arrow_schema ( arrow_schema ) : retur...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           docstring  \\\n",
       "0  Returns an array of bounding boxes of human fa...   \n",
       "1  Returns an array of bounding boxes of human fa...   \n",
       "2  Return the Catalyst datatype from the size of ...   \n",
       "3               Convert a schema from Spark to Arrow   \n",
       "4                Convert schema from Arrow to Spark.   \n",
       "\n",
       "                                            function  \\\n",
       "0  def _raw_face_locations(img, number_of_times_t...   \n",
       "1  def face_locations(img, number_of_times_to_ups...   \n",
       "2  def _int_size_to_type(size):\\n    \"\"\"\\n    Ret...   \n",
       "3  def to_arrow_schema(schema):\\n    \"\"\" Convert ...   \n",
       "4  def from_arrow_schema(arrow_schema):\\n    \"\"\" ...   \n",
       "\n",
       "                                   docstring_cleaned  docstring_isEnglish  \\\n",
       "0  returns an array of bounding boxes of human fa...                 True   \n",
       "1  returns an array of bounding boxes of human fa...                 True   \n",
       "2  return the catalyst datatype from the size of ...                 True   \n",
       "3               convert a schema from spark to arrow                 True   \n",
       "4                 convert schema from arrow to spark                 True   \n",
       "\n",
       "                                    function_cleaned  \n",
       "0  def _raw_face_locations ( img , number_of_time...  \n",
       "1  def face_locations ( img , number_of_times_to_...  \n",
       "2  def _int_size_to_type ( size ) : if size < = 8...  \n",
       "3  def to_arrow_schema ( schema ) : import pyarro...  \n",
       "4  def from_arrow_schema ( arrow_schema ) : retur...  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "codenet.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "sheet_delimiter": false
    }
   },
   "source": [
    "*Removing any hiddle characters*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "datalore": {
     "sheet_delimiter": false
    }
   },
   "outputs": [],
   "source": [
    "codenet['function_cleaned'] = codenet['function_cleaned'].apply(lambda x: ''.join(line for line in x if line in string.printable))\n",
    "codenet['docstring_cleaned'] = codenet['docstring_cleaned'].apply(lambda x: ''.join(line for line in x if line in string.printable))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "datalore": {
     "sheet_delimiter": false
    }
   },
   "outputs": [],
   "source": [
    "### Saving the dataset to the data dir\n",
    "# codenet[['docstring','docstring_cleaned','function','function_cleaned']].to_csv(os.path.join(data_dir, 'CodeNetData_cleaned.csv'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
